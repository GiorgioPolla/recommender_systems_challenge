{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy as sc\n",
    "import numpy as np\n",
    "import sys\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# addresses of the files\n",
    "train_file = '../data/train.csv'\n",
    "target_playlists_file = '../data/target_playlists.csv'\n",
    "tracks_file = '../data/tracks.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading of all files and renaming columns\n",
    "train_data = pd.read_csv(train_file)\n",
    "train_data.columns = ['playlist_id', 'track_id']\n",
    "\n",
    "tracks_data = pd.read_csv(tracks_file)\n",
    "tracks_data.columns = ['track_id', 'album_id', 'artist_id', 'duration_sec']\n",
    "\n",
    "target_playlists = pd.read_csv(target_playlists_file)\n",
    "target_playlists.columns = ['playlist_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building the URM matrix\n",
    "grouped_playlists = train_data.groupby('playlist_id', as_index=True).apply(lambda x: list(x['track_id']))\n",
    "URM = MultiLabelBinarizer(sparse_output=True).fit_transform(grouped_playlists)\n",
    "URM_csr = URM.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building the similarity matrix\n",
    "similarity_matrix = URM_csr.dot(URM_csr.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_output_file():\n",
    "    file = open(\"submission.csv\", 'a')\n",
    "    file.write(\"playlist_id,track_ids\" + '\\n')\n",
    "    return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful to print to file with the right structure\n",
    "def print_to_file(playlist, tracks, file):\n",
    "    file.write(str(playlist) + ',')\n",
    "    index = 0\n",
    "    while index < 9:\n",
    "        file.write(str(tracks[index]) + ' ')\n",
    "        index += 1\n",
    "    file.write(str(tracks[index]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(playlist_id, playlists):\n",
    "    target_playlist = grouped_playlists.loc[playlist_id]\n",
    "    \n",
    "    row_data = similarity_matrix[playlist_id,:]\n",
    "\n",
    "    reverse_similarity_ranking = np.argsort(row_data.todense())\n",
    "\n",
    "    reverse_ranking_array = np.squeeze(np.asarray(reverse_similarity_ranking))\n",
    "    \n",
    "    similarity_ranking = reverse_ranking_array[::-1]\n",
    "\n",
    "    to_be_recommended = []\n",
    "    \n",
    "    recommendations = 0\n",
    "    index = 1\n",
    "    while(recommendations < 10):\n",
    "        pos = similarity_ranking[index]\n",
    "        considered_playlist = playlists.loc[pos]\n",
    "        index += 1\n",
    "        for track in considered_playlist:\n",
    "            if track not in target_playlist and recommendations < 10:\n",
    "                recommendations += 1\n",
    "                to_be_recommended.append(track)\n",
    "    \n",
    "    return to_be_recommended\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execution of the recommendations\n",
    "file = initialize_output_file()\n",
    "\n",
    "for playlist in target_playlists.itertuples(index=True, name='Pandas'):\n",
    "    playlist_id = getattr(playlist, \"playlist_id\")\n",
    "    to_be_recommended = recommend(playlist_id, grouped_playlists)\n",
    "    print_to_file(playlist_id, to_be_recommended, file)\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(is_relevant, relevant_items):\n",
    "\n",
    "    #is_relevant = np.in1d(recommended_items, relevant_items, assume_unique=True)\n",
    "\n",
    "    precision_score = np.sum(is_relevant, dtype=np.float32) / len(is_relevant)\n",
    "\n",
    "    return precision_score\n",
    "\n",
    "\n",
    "\n",
    "def recall(is_relevant, relevant_items):\n",
    "\n",
    "    #is_relevant = np.in1d(recommended_items, relevant_items, assume_unique=True)\n",
    "\n",
    "    recall_score = np.sum(is_relevant, dtype=np.float32) / relevant_items.shape[0]\n",
    "\n",
    "    return recall_score\n",
    "\n",
    "\n",
    "\n",
    "def MAP(is_relevant, relevant_items):\n",
    "\n",
    "    #is_relevant = np.in1d(recommended_items, relevant_items, assume_unique=True)\n",
    "\n",
    "    # Cumulative sum: precision at 1, at 2, at 3 ...\n",
    "    p_at_k = is_relevant * np.cumsum(is_relevant, dtype=np.float32) / (1 + np.arange(is_relevant.shape[0]))\n",
    "\n",
    "    map_score = np.sum(p_at_k) / np.min([relevant_items.shape[0], is_relevant.shape[0]])\n",
    "\n",
    "    return map_score\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_algorithm(URM_test):\n",
    "\n",
    "    cumulative_precision = 0.0\n",
    "    cumulative_recall = 0.0\n",
    "    cumulative_MAP = 0.0\n",
    "\n",
    "    num_eval = 0\n",
    "\n",
    "    n_users = URM_test.shape[0]\n",
    "\n",
    "\n",
    "    for user_id in range(n_users):\n",
    "\n",
    "        if user_id % 10000 == 0:\n",
    "            print(\"Evaluated user {} of {}\".format(user_id, n_users))\n",
    "\n",
    "        start_pos = URM_test.indptr[user_id]\n",
    "        end_pos = URM_test.indptr[user_id+1]\n",
    "\n",
    "        if end_pos-start_pos>0:\n",
    "\n",
    "            relevant_items = URM_test.indices[start_pos:end_pos]\n",
    "\n",
    "            recommended_items = recommend(user_id, grouped_playlists)\n",
    "            num_eval+=1\n",
    "\n",
    "            is_relevant = np.in1d(recommended_items, relevant_items, assume_unique=True)\n",
    "\n",
    "            cumulative_precision += precision(is_relevant, relevant_items)\n",
    "            cumulative_recall += recall(is_relevant, relevant_items)\n",
    "            cumulative_MAP += MAP(is_relevant, relevant_items)\n",
    "\n",
    "\n",
    "    cumulative_precision /= num_eval\n",
    "    cumulative_recall /= num_eval\n",
    "    cumulative_MAP /= num_eval\n",
    "\n",
    "    print(\"Recommender performance is: Precision = {:.4f}, Recall = {:.4f}, MAP = {:.4f}\".format(\n",
    "        cumulative_precision, cumulative_recall, cumulative_MAP))\n",
    "\n",
    "    result_dict = {\n",
    "        \"precision\": cumulative_precision,\n",
    "        \"recall\": cumulative_recall,\n",
    "        \"MAP\": cumulative_MAP,\n",
    "    }\n",
    "\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_splitter import train_test_holdout\n",
    "\n",
    "URM_train, URM_test = train_test_holdout(URM_csr, train_perc = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated user 0 of 50446\n",
      "Evaluated user 10000 of 50446\n",
      "Evaluated user 20000 of 50446\n",
      "Evaluated user 30000 of 50446\n",
      "Evaluated user 40000 of 50446\n",
      "Evaluated user 50000 of 50446\n",
      "Recommender performance is: Precision = 0.0002, Recall = 0.0001, MAP = 0.0002\n",
      "Time required 0.64 min\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "evaluate_algorithm(URM_test)\n",
    "\n",
    "print(\"Time required {:.2f} min\".format((time.time()-start_time)/60))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
